{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af595504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Installing protobuf...\n",
      "✅ tiktoken is already installed\n",
      "✅ sentencepiece is already installed\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def ensure_package(pkg):\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "        print(f\"{pkg} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for package in [\"protobuf\", \"tiktoken\", \"sentencepiece\"]:\n",
    "    ensure_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d626e4a",
   "metadata": {
    "id": "9d626e4a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForMultipleChoice, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForMultipleChoice,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ecbe9",
   "metadata": {
    "id": "285ecbe9"
   },
   "outputs": [],
   "source": [
    "root_path = \"./essay-gap\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "MAX_LEN = 256\n",
    "BATCH_SIZE = 2\n",
    "GRADIENT_ACCUMULATION_STEPS = 4 # 2x4=8 effective batch size\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 5e-6\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9188d",
   "metadata": {
    "id": "b3b9188d"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayGapDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, is_test=False):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "                \n",
    "        first_sentences = [str(row['before'])] * 4\n",
    "        second_sentences = [\n",
    "            str(row[f'opt_{i}']) + \" \" + str(row['after']) for i in range(4)\n",
    "        ]\n",
    "\n",
    "        tokenized_examples = self.tokenizer(\n",
    "            first_sentences, \n",
    "            second_sentences, \n",
    "            truncation=True, \n",
    "            max_length=MAX_LEN, \n",
    "            padding=\"max_length\"\n",
    "        )\n",
    "        \n",
    "        batch = {k: v for k, v in tokenized_examples.items()}\n",
    "        \n",
    "        if not self.is_test:\n",
    "            batch['label'] = int(row['label'])\n",
    "        else:\n",
    "            batch['label'] = 0\n",
    "            \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99c3653",
   "metadata": {
    "id": "f99c3653",
    "outputId": "ebc521a0-9926-4615-84ac-319941dfb4c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 32, 80)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_full = pd.read_csv(f\"{root_path}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{root_path}/test.csv\")\n",
    "train_df, val_df = train_test_split(train_df_full, test_size=0.1, random_state=42)\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096149c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56ef3989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YuXuan\\AppData\\Local\\Python\\pythoncore-3.12-64\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset = EssayGapDataset(train_df, tokenizer)\n",
    "val_dataset = EssayGapDataset(val_df, tokenizer)\n",
    "test_dataset = EssayGapDataset(test_df, tokenizer, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YuXuan\\AppData\\Local\\Temp\\ipykernel_31816\\2805385226.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 01:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.437507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.122964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.135892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=360, training_loss=0.025969401995340983, metrics={'train_runtime': 102.3168, 'train_samples_per_second': 14.074, 'train_steps_per_second': 3.518, 'total_flos': 381512894054400.0, 'train_loss': 0.025969401995340983, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "338780c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Predicting on test set...\")\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds_indices = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa5cc7",
   "metadata": {
    "id": "d8fa5cc7"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2d1a2bb",
   "metadata": {
    "id": "b2d1a2bb",
    "outputId": "0b45849a-144a-4a9b-a0f9-043edc1c1567"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampleID  answer\n",
       "0       100       0\n",
       "1       101       0\n",
       "2       102       2\n",
       "3       103       0\n",
       "4       104       3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"sampleID\": test_df[\"sampleID\"], \"answer\": preds_indices})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b384a0c",
   "metadata": {
    "id": "2b384a0c"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
