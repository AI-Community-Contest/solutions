{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7efab92",
   "metadata": {},
   "source": [
    "# Essay gap\n",
    "\n",
    "Solution author: Asandei Stefan-Alexandru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d626e4a",
   "metadata": {
    "id": "9d626e4a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285ecbe9",
   "metadata": {
    "id": "285ecbe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe79f938950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path = \"/home/stefan/ioai-prep/kits/essay-gap\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "seed = 42\n",
    "torch.random.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d65e6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a1cafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9188d",
   "metadata": {
    "id": "b3b9188d"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99c3653",
   "metadata": {
    "id": "f99c3653",
    "outputId": "ebc521a0-9926-4615-84ac-319941dfb4c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleID</th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "      <th>opt_0</th>\n",
       "      <th>opt_1</th>\n",
       "      <th>opt_2</th>\n",
       "      <th>opt_3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The life cycle of a Christmas tree from the se...</td>\n",
       "      <td>One issue that farmers face is the destruction...</td>\n",
       "      <td>The remaining development of the tree greatly ...</td>\n",
       "      <td>The belief in the divinity of Jesus leads to t...</td>\n",
       "      <td>Essentially the recipe brings together what tr...</td>\n",
       "      <td>It is a matter of some debate as to which was ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Slopes flatter than 25 degrees or steeper than...</td>\n",
       "      <td>The rule of thumb is: A slope that is flat eno...</td>\n",
       "      <td>In her 1850 book The First Christmas in New En...</td>\n",
       "      <td>In Latin America and the Iberian Peninsula, th...</td>\n",
       "      <td>On steeper slopes, this can occur with as litt...</td>\n",
       "      <td>When the incidence of human triggered avalanch...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Most workplaces conduct a \"Christmas Party\" so...</td>\n",
       "      <td>Likewise, schools, TAFE (vocational training),...</td>\n",
       "      <td>As many people take their holidays between Chr...</td>\n",
       "      <td>The frequency with which avalanches form in a ...</td>\n",
       "      <td>In doing so, they employ on-the-ground physica...</td>\n",
       "      <td>The area in and around the basilica begins to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Chronography of 354 illuminated manuscript...</td>\n",
       "      <td>By around 385 the feast for the birth of Jesus...</td>\n",
       "      <td>The eastern inland region where the country is...</td>\n",
       "      <td>In a sermon delivered in Antioch on December 2...</td>\n",
       "      <td>This remains one of the most extensive such ma...</td>\n",
       "      <td>A cold front, the leading edge of a cooler mas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>English personifications of Christmas were fir...</td>\n",
       "      <td>His character was maintained during the late 1...</td>\n",
       "      <td>In a sermon in 386, Gregory of Nyssa specifica...</td>\n",
       "      <td>The first evidence of decorated trees associat...</td>\n",
       "      <td>Following the Restoration in 1660, Father Chri...</td>\n",
       "      <td>In 614, the Persian Sassanid Empire, supported...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampleID                                             before  \\\n",
       "0         0  The life cycle of a Christmas tree from the se...   \n",
       "1         1  Slopes flatter than 25 degrees or steeper than...   \n",
       "2         2  Most workplaces conduct a \"Christmas Party\" so...   \n",
       "3         3  The Chronography of 354 illuminated manuscript...   \n",
       "4         4  English personifications of Christmas were fir...   \n",
       "\n",
       "                                               after  \\\n",
       "0  One issue that farmers face is the destruction...   \n",
       "1  The rule of thumb is: A slope that is flat eno...   \n",
       "2  Likewise, schools, TAFE (vocational training),...   \n",
       "3  By around 385 the feast for the birth of Jesus...   \n",
       "4  His character was maintained during the late 1...   \n",
       "\n",
       "                                               opt_0  \\\n",
       "0  The remaining development of the tree greatly ...   \n",
       "1  In her 1850 book The First Christmas in New En...   \n",
       "2  As many people take their holidays between Chr...   \n",
       "3  The eastern inland region where the country is...   \n",
       "4  In a sermon in 386, Gregory of Nyssa specifica...   \n",
       "\n",
       "                                               opt_1  \\\n",
       "0  The belief in the divinity of Jesus leads to t...   \n",
       "1  In Latin America and the Iberian Peninsula, th...   \n",
       "2  The frequency with which avalanches form in a ...   \n",
       "3  In a sermon delivered in Antioch on December 2...   \n",
       "4  The first evidence of decorated trees associat...   \n",
       "\n",
       "                                               opt_2  \\\n",
       "0  Essentially the recipe brings together what tr...   \n",
       "1  On steeper slopes, this can occur with as litt...   \n",
       "2  In doing so, they employ on-the-ground physica...   \n",
       "3  This remains one of the most extensive such ma...   \n",
       "4  Following the Restoration in 1660, Father Chri...   \n",
       "\n",
       "                                               opt_3  label  \n",
       "0  It is a matter of some debate as to which was ...      0  \n",
       "1  When the incidence of human triggered avalanch...      3  \n",
       "2  The area in and around the basilica begins to ...      0  \n",
       "3  A cold front, the leading edge of a cooler mas...      1  \n",
       "4  In 614, the Persian Sassanid Empire, supported...      2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(f\"{root_path}/train.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "046915f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=512):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        before = row[\"before\"]\n",
    "        after = row[\"after\"]\n",
    "        if \"label\" in row:\n",
    "            label = row[\"label\"]\n",
    "\n",
    "        encodings = []\n",
    "        for i in range(4):\n",
    "            option = row[f\"opt_{i}\"]\n",
    "            text = f\"{before} [SEP] {option} [SEP] {after}\"\n",
    "\n",
    "            enc = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            encodings.append(\n",
    "                {\n",
    "                    \"input_ids\": enc[\"input_ids\"].squeeze(),\n",
    "                    \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if \"label\" in row:\n",
    "            return {\n",
    "                \"input_ids\": torch.stack([e[\"input_ids\"] for e in encodings]),\n",
    "                \"attention_mask\": torch.stack([e[\"attention_mask\"] for e in encodings]),\n",
    "                \"label\": torch.tensor(label, dtype=torch.long),\n",
    "            }\n",
    "        return {\n",
    "            \"input_ids\": torch.stack([e[\"input_ids\"] for e in encodings]),\n",
    "            \"attention_mask\": torch.stack([e[\"attention_mask\"] for e in encodings]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0917cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_dataset = EssayDataset(train_df, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a9d71",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a9be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "lr = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9056685d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 40/40 [00:29<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 40/40 [00:29<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Loss: 0.6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 40/40 [00:28<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Loss: 0.1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Shape: (batch_size, 4, seq_len)\n",
    "        batch_size, num_options, seq_len = input_ids.shape\n",
    "\n",
    "        # Reshape to (batch_size * 4, seq_len)\n",
    "        input_ids_flat = input_ids.view(batch_size * num_options, seq_len)\n",
    "        attention_mask_flat = attention_mask.view(batch_size * num_options, seq_len)\n",
    "\n",
    "        outputs = model(input_ids=input_ids_flat, attention_mask=attention_mask_flat)\n",
    "        logits = outputs.logits  # (batch_size * 4, 4)\n",
    "\n",
    "        # Reshape back and take logits for each option\n",
    "        logits = logits.view(batch_size, num_options, -1)\n",
    "        logits = logits[:, :, 0]  # Take class 0 logits for each option\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa5cc7",
   "metadata": {
    "id": "d8fa5cc7"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cdcf8f",
   "metadata": {
    "id": "35cdcf8f"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(f\"{root_path}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e77948b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 10/10 [00:02<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "test_dataset = EssayDataset(test_df, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        batch_size, num_options, seq_len = input_ids.shape\n",
    "        input_ids_flat = input_ids.view(batch_size * num_options, seq_len)\n",
    "        attention_mask_flat = attention_mask.view(batch_size * num_options, seq_len)\n",
    "\n",
    "        outputs = model(input_ids=input_ids_flat, attention_mask=attention_mask_flat)\n",
    "        logits = outputs.logits.view(batch_size, num_options, -1)[:, :, 0]\n",
    "\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2d1a2bb",
   "metadata": {
    "id": "b2d1a2bb",
    "outputId": "0b45849a-144a-4a9b-a0f9-043edc1c1567"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sampleID  answer\n",
       "0       100       0\n",
       "1       101       0\n",
       "2       102       2\n",
       "3       103       0\n",
       "4       104       3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"sampleID\": test_df[\"sampleID\"], \"answer\": predictions})\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b384a0c",
   "metadata": {
    "id": "2b384a0c"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
