{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92654de2",
      "metadata": {
        "id": "92654de2",
        "papermill": {
          "duration": 0.006695,
          "end_time": "2025-12-28T08:39:37.051913",
          "exception": false,
          "start_time": "2025-12-28T08:39:37.045218",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ca19c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-28T08:39:37.065600Z",
          "iopub.status.busy": "2025-12-28T08:39:37.065300Z",
          "iopub.status.idle": "2025-12-28T08:40:50.922820Z",
          "shell.execute_reply": "2025-12-28T08:40:50.921774Z"
        },
        "id": "c0ca19c1",
        "outputId": "7574f3a2-bebd-44c1-c284-591e8d7ff7d7",
        "papermill": {
          "duration": 73.866417,
          "end_time": "2025-12-28T08:40:50.924845",
          "exception": false,
          "start_time": "2025-12-28T08:39:37.058428",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "92e22027645443efa12fd2c6a64b29ee",
            "4e885c7952634e8284769fce54ee26a4",
            "c29b3b0418554b1982c9651c455a22bf"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training signals...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92e22027645443efa12fd2c6a64b29ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "X_train:   0%|          | 0/949 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchaudio/_backend/ffmpeg.py:88: UserWarning: torio.io._streaming_media_decoder.StreamingMediaDecoder has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
            "  s = torchaudio.io.StreamReader(src, format, None, buffer_size)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e885c7952634e8284769fce54ee26a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Y1_train:   0%|          | 0/949 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c29b3b0418554b1982c9651c455a22bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Y2_train:   0%|          | 0/949 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test signals...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "K = 16000\n",
        "IN_DIR = \"/kaggle/input/audio-demixing-aicc-round-2/\"\n",
        "\n",
        "def load_signal(path, K):\n",
        "    wav, _ = torchaudio.load(path)\n",
        "    arr = wav[0].numpy()\n",
        "    if len(arr) >= K:\n",
        "        return arr[:K].astype(np.float32)\n",
        "    else:\n",
        "        return np.pad(arr, (0, K - len(arr)), mode='constant').astype(np.float32)\n",
        "\n",
        "# Load CSVs\n",
        "train = pd.read_csv(\"/kaggle/input/audio-demixing-aicc-round-2/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/audio-demixing-aicc-round-2/test.csv\")\n",
        "\n",
        "# Load raw training signals\n",
        "print(\"Loading training signals...\")\n",
        "X_train = np.vstack([load_signal(os.path.join(IN_DIR, p), K) for p in tqdm(train[\"file\"], desc=\"X_train\")])\n",
        "Y1_train = np.vstack([load_signal(os.path.join(IN_DIR, p), K) for p in tqdm(train[\"sig_1\"], desc=\"Y1_train\")])\n",
        "Y2_train = np.vstack([load_signal(os.path.join(IN_DIR, p), K) for p in tqdm(train[\"sig_2\"], desc=\"Y2_train\")])\n",
        "\n",
        "# Load raw test signals\n",
        "print(\"Loading test signals...\")\n",
        "if \"sig_1\" in test.columns:\n",
        "    X_test = np.vstack([load_signal(os.path.join(IN_DIR, p), K) for p in tqdm(test[\"sig_1\"], desc=\"X_test\")])\n",
        "else:\n",
        "    X_test = np.tile(X_train[0], (len(test), 1))\n",
        "\n",
        "test_IDs = test[\"ID\"].astype(str).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c28c32",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-28T08:40:50.938929Z",
          "iopub.status.busy": "2025-12-28T08:40:50.938364Z",
          "iopub.status.idle": "2025-12-28T08:40:52.932455Z",
          "shell.execute_reply": "2025-12-28T08:40:52.931674Z"
        },
        "id": "e1c28c32",
        "outputId": "0d981e4e-a0a9-41ee-8cc9-c12b25a74228",
        "papermill": {
          "duration": 2.003444,
          "end_time": "2025-12-28T08:40:52.934411",
          "exception": false,
          "start_time": "2025-12-28T08:40:50.930967",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Ridge models...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Flatten for single-step regression\n",
        "X_flat = X_train.reshape(-1, 1)\n",
        "Y1_flat = Y1_train.reshape(-1)\n",
        "Y2_flat = Y2_train.reshape(-1)\n",
        "\n",
        "# Train Ridge regressors\n",
        "print(\"Training Ridge models...\")\n",
        "m1 = Ridge(alpha=1.0)\n",
        "m2 = Ridge(alpha=1.0)\n",
        "m1.fit(X_flat, Y1_flat)\n",
        "m2.fit(X_flat, Y2_flat)\n",
        "\n",
        "# Predict on raw test signals\n",
        "X_test_flat = X_test.reshape(-1, 1)\n",
        "pred1_flat = m1.predict(X_test_flat)\n",
        "pred2_flat = m2.predict(X_test_flat)\n",
        "\n",
        "pred1 = pred1_flat.reshape(len(X_test), K).astype(np.float32)\n",
        "pred2 = pred2_flat.reshape(len(X_test), K).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d7ab5a2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-12-28T08:40:52.949981Z",
          "iopub.status.busy": "2025-12-28T08:40:52.949084Z",
          "iopub.status.idle": "2025-12-28T08:40:53.824149Z",
          "shell.execute_reply": "2025-12-28T08:40:53.823171Z"
        },
        "id": "1d7ab5a2",
        "outputId": "be2684f5-4eb1-4205-e349-96f9d4475e61",
        "papermill": {
          "duration": 0.885441,
          "end_time": "2025-12-28T08:40:53.825906",
          "exception": false,
          "start_time": "2025-12-28T08:40:52.940465",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "a64678ff4507438d8fb4658e2cbb0d2b"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a64678ff4507438d8fb4658e2cbb0d2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Encoding rows:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ submission.csv written\n"
          ]
        }
      ],
      "source": [
        "import base64\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import csv\n",
        "\n",
        "def encode_array_base85(arr: np.ndarray) -> str:\n",
        "    arr = np.ascontiguousarray(arr.astype(np.float32).ravel())\n",
        "    return base64.b85encode(arr.tobytes()).decode(\"ascii\")\n",
        "\n",
        "# Encode predictions\n",
        "rows = []\n",
        "for i in tqdm(range(len(test_IDs)), desc=\"Encoding rows\"):\n",
        "    b1 = encode_array_base85(pred1[i])\n",
        "    b2 = encode_array_base85(pred2[i])\n",
        "    rows.append((str(test_IDs[i]), b1, b2))\n",
        "\n",
        "# Build submission DataFrame\n",
        "submission = pd.DataFrame(rows, columns=[\"ID\", \"sig_1\", \"sig_2\"])\n",
        "submission.to_csv(\"/kaggle/working/submission.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
        "print(\"✓ submission.csv written\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 15120545,
          "sourceId": 124592,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31234,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 82.376488,
      "end_time": "2025-12-28T08:40:56.302984",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-12-28T08:39:33.926496",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}